{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Батч нормализация"
      ],
      "metadata": {
        "id": "RFKd3mZ4JaVM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v50SjCbZHC8y"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequental([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Использование предобученной модели. transfer learning"
      ],
      "metadata": {
        "id": "iWb1hMdWJZcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_A = keras.models.load_model(\"model_A.h5\") # Или .keras\n",
        "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
        "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\")) # удаление многоклассового выхода и добавление бинарного"
      ],
      "metadata": {
        "id": "FuDoYXD-Kcv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Для того чтобы модель А не изменялась(веса), необходимо клонировать модель"
      ],
      "metadata": {
        "id": "VMEFCG7LLKQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone = keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ],
      "metadata": {
        "id": "ecDqdaglLjRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из-за того, что новый слой был инициализирован случаным образом, необходимо заморозимть слои для узнавания приемлемых весов"
      ],
      "metadata": {
        "id": "xeebohJsMWEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_B_on_A.layers[:-1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B))"
      ],
      "metadata": {
        "id": "3bs3hqScMBzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "При разморозке весов, lr уменьшается, чтобы сильно не изменять веса модели"
      ],
      "metadata": {
        "id": "bVNovTh5OpBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_B_on_A.layers[:-1]:\n",
        "  layer.trainable = True\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=1e-4) # старая версия, смотреть 7 тетрадь\n",
        "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16, validation_data=(X_valid_B, y_valid_B))"
      ],
      "metadata": {
        "id": "y_QnRbohNmjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценка. Transfer learning лучше работает, при CNN"
      ],
      "metadata": {
        "id": "fPI-whz6OyaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_B_on_A.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "id": "q_NydRaCO2zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Оптимизаторы GD"
      ],
      "metadata": {
        "id": "2D06PUR5kUdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Momentum optimization of GD\n",
        "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
        "\n",
        "# Nesterov Accelerated Gradient | NAG\n",
        "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "\n",
        "# AdaGrad\n",
        "\n",
        "# RMSProp\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "\n",
        "# Adam\n",
        "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# AdaMax - Заменяет норму L2, на Норму L(inf), использует максимальное затухание градиентов во времени\n",
        "# Nadam - оптимизация Adam + трюк Нестерова"
      ],
      "metadata": {
        "id": "E_NFp3YajOi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Оптимизация lr, во время обучения"
      ],
      "metadata": {
        "id": "2ypIshFcpAwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)\n",
        "\n",
        "def exponentioal_decay_fn(epoch):\n",
        "  return 0.01 * 0.1**(epoch/20)\n",
        "\n",
        "# если не хотим жёстко кодировать n0 и s\n",
        "def exponential_decay(lr0, s):\n",
        "  def exponentioal_decay_fn(epoch):\n",
        "    return lr0 * 0.1**(epoch / s)\n",
        "  return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
        "\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "history = model.fit(..., callbacks=[lr_scheduler])\n",
        "\n",
        "# кусочно-линейный постоянный график\n",
        "def piecewise_constant_fn(epoch):\n",
        "  if epoch < 5:\n",
        "    return 0.01\n",
        "  elif epoch < 15:\n",
        "    return 0.005\n",
        "  else:\n",
        "    return 0.001\n",
        "\n",
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "\n",
        "# обновление lr на каждом шаге\n",
        "s = 20 * len(X_train) // 32\n",
        "\n",
        "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
        "optimizer = keras.optimizers.SGD(learning_rate)"
      ],
      "metadata": {
        "id": "HPb3mbRbpK2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Регуляризация L1, L2"
      ],
      "metadata": {
        "id": "T5CoyY2vtMsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Densse(100, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "\n",
        "# keras.regularizers.l1()\n",
        "# keras.regularizers.l1_l2() 2 коэффицента регуляризации"
      ],
      "metadata": {
        "id": "pw53E0WTU4GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Functools import partial\n",
        "\n",
        "RegularizedDense = partial(\n",
        "    keras.layers.Dense,\n",
        "    activation=\"elu\",\n",
        "    kernel_initializer=\"he_normal\",\n",
        "    kernel_regularizer=keras.regularizers.l2(0.01)\n",
        ")\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    RegularizedDense(300),\n",
        "    RegularizedDense(100),\n",
        "    RegularizedDense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
        "])"
      ],
      "metadata": {
        "id": "gDebCKYlXLyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout"
      ],
      "metadata": {
        "id": "_DVIMxXkYTkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dropout(rate=0.2), # rate = proba %\n",
        "    RegularizedDense(300),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    RegularizedDense(100),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    RegularizedDense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
        "])"
      ],
      "metadata": {
        "id": "-1FgBJjjYS9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MC Dropout | Monte Carlo Dropout"
      ],
      "metadata": {
        "id": "iqOz3KQfYl-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_probas = np.stack([model(X_test_scaled, training=True) for sample in range(100)]) # [100, 10 000, 10]\n",
        "y_proba = y_proba.mean(axis=0) # [10 000, 10]"
      ],
      "metadata": {
        "id": "h4JB07FJYwSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MCDropout(keras.layers.Dropout):\n",
        "  def call(self, inputs):\n",
        "    return super().call(inputs, training=True)"
      ],
      "metadata": {
        "id": "u1OQw-5tZVyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max Norm"
      ],
      "metadata": {
        "id": "SdvJP5ceZs6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.Dense(\n",
        "    100, activation=\"elu\",\n",
        "    kernel_initializer=\"he_normal\",\n",
        "    kernel_constraints.max_norm(1.)\n",
        ")"
      ],
      "metadata": {
        "id": "B_6LCHVpZsF6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}