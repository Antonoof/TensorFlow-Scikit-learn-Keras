{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "_1MBoDbm1aUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOa5Hnzj06d8",
        "outputId": "061f4bbe-62ab-4754-a332-a3331ac31f3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X = tf.range(10)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in dataset:\n",
        "  print(item)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNCZ1Lhj1Wgj",
        "outputId": "0782620c-10ab-48f4-dd50-1781b6e2be46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.repeat(3).batch(7) # drop_remainder=True отбросит последний пакет(неполный)\n",
        "\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-8Sg__Y17ku",
        "outputId": "7e5337e0-5d39-46c6-c2ac-09038254dc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.apply(tf.data.experimental.unbatch())\n",
        "\n",
        "for item in dataset:\n",
        "  print(item, end=' ')\n",
        "\n",
        "dataset = dataset.filter(lambda x: x < 10)\n",
        "\n",
        "print('\\nFiltered')\n",
        "\n",
        "for item in dataset.take(3):\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ9tvvLZ-X3M",
        "outputId": "42b2581b-aafe-40ed-bf0b-e8fef0f23e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(2, shape=(), dtype=int32) tf.Tensor(3, shape=(), dtype=int32) tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(5, shape=(), dtype=int32) tf.Tensor(6, shape=(), dtype=int32) tf.Tensor(7, shape=(), dtype=int32) tf.Tensor(8, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32) tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(2, shape=(), dtype=int32) tf.Tensor(3, shape=(), dtype=int32) tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(5, shape=(), dtype=int32) tf.Tensor(6, shape=(), dtype=int32) tf.Tensor(7, shape=(), dtype=int32) tf.Tensor(8, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32) tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(2, shape=(), dtype=int32) tf.Tensor(3, shape=(), dtype=int32) tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(5, shape=(), dtype=int32) tf.Tensor(6, shape=(), dtype=int32) tf.Tensor(7, shape=(), dtype=int32) tf.Tensor(8, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32) \n",
            "Filtered\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(10).repeat(3) # от 0 до 9, три раза\n",
        "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
        "\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgIB1-1MAeRr",
        "outputId": "8fa0134f-215a-4357-a952-01ad6ebf2164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([3 6], shape=(2,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Команда shuf в Linux перемешает строки в файле**\n",
        "\n",
        "```\n",
        "shuf file.txt or shuf file.txt -o shuffled_file.txt\n",
        "```"
      ],
      "metadata": {
        "id": "HGv_mE_SFJ3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка и предварительная обработка данных из множества файлов CSV"
      ],
      "metadata": {
        "id": "25eK8aKWe2Sm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "prefetch(1) помогает подготавливать данные на CPU, а обучать на GPU. Тем самым ускоряя подачу данных для обучения"
      ],
      "metadata": {
        "id": "jnnpjOrDhGMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_reader_dataset(filepaths, repeat=1, n_readers=5, n_read_threads=None, shuffle_buffer_size=1e4, n_parse_threads=5, batch_size=32):\n",
        "  dataset = tf.data.Dataset.list_files(filepaths)\n",
        "  # Соединяем файлы для перемешивания\n",
        "  dataset = dataset.interleave(\n",
        "      lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "      cycle_length=n_readers, num_parallel_calls=n_parse_threads\n",
        "  )\n",
        "  dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "  dataset = dataset.shuflle(shuffle_buffer_size).repeat(repeat)\n",
        "  return dataset.batch(batchsize).prefetch(1)"
      ],
      "metadata": {
        "id": "ZlhjJz8SD2hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение входного конвейера с API Data"
      ],
      "metadata": {
        "id": "VKCP95fFk5p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train(model, opimizer, loss_fn, n_epochs, [...]):\n",
        "  train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, [...])\n",
        "  for X_batch, y_batch in train_set:\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = model(X_batch)\n",
        "      main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "      loss = tf.add_n([main_loss] + model.losses)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ],
      "metadata": {
        "id": "nOvURUSXlEPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF Record - Формат в TensorFlow для хранения очень крупных объемов данных и их эффективного чтения.\n",
        "\n",
        "Использует CRC для проверки повреждения"
      ],
      "metadata": {
        "id": "ru-oQpjgnMo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
        "  f.write(b\"This is the first record\")\n",
        "  f.write(b\"And this is the second record\")"
      ],
      "metadata": {
        "id": "xQlkVU3dnn9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.data.TFRecordDataset - чтение одного и более файлов TFRecord"
      ],
      "metadata": {
        "id": "a3xPrEQ7oCEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = [\"my_data.tfrecord\"]\n",
        "dataset = tf.data.TFRecordDataset(filepaths)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "xm_J09dnoINg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Hot Encoding - немного категориальных признаков\n",
        "\n",
        "Embedding - много категориальных признаков"
      ],
      "metadata": {
        "id": "Ey1r2jV5JvZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\"])\n",
        "cat_indices = take.lookup(categories)\n",
        "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + 2) # + 2 т.к всего 5 признаков"
      ],
      "metadata": {
        "id": "qXSnc88TJ23J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 2 # двумерные вложения\n",
        "embed_init = tf.random.uniform([len(vocab) + 2, embedding_dim]) # матрица [n, dim] где n количество признаков\n",
        "embedding_matrix = tf.Variable(embed_init) # пример [0.654, 0.443] * 5(random)\n",
        "\n",
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\"])\n",
        "cat_indices = take.lookup(categories)\n",
        "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
      ],
      "metadata": {
        "id": "6hpDlUbQKrR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = keras.layers.Embedding(input_dim=len(vocab) + 2, output_dim=embedding_dim)\n",
        "embedding(cat_indices)"
      ],
      "metadata": {
        "id": "V9yLrzbxMUhS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
